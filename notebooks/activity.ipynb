{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Module  \n",
    "\n",
    "This notebook reflects the code that is applied in the Activity Module for the application. In this noteb the plan is to develop the same results but using incremental steps with explanations of what is occurring and where you can get supporting documentation.  \n",
    "\n",
    "The first step is to get all the python packages that will need to be used for the module and effectively activate them for use.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from app.utility.helps import Bob\n",
    "from app.utility.file_management import File_Management\n",
    "from app.utility.fabric import File_Table_Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting settings and context  \n",
    "The settings have information that your service principal will use to write information to your lakehouse files. The context is the tokens used by the APIs to verify your access rights to the data that is retrieved from the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred while reading the file: 'ServicePrincipal'\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'tenant_id' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m bob \u001b[38;5;241m=\u001b[39m Bob()\n\u001b[1;32m      2\u001b[0m settings \u001b[38;5;241m=\u001b[39m bob\u001b[38;5;241m.\u001b[39mget_settings()\n\u001b[0;32m----> 3\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[43mbob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/fabric/monitor/public/FabricMonitorPublic/notebooks/../app/utility/helps.py:53\u001b[0m, in \u001b[0;36mBob.get_context\u001b[0;34m(self, graph, tenant)\u001b[0m\n\u001b[1;32m     50\u001b[0m     scope \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.fabric.microsoft.com/.default\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m#authority = f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token?api-version=1.0\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     authority \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://login.microsoftonline.com/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtenant_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m     scope \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://analysis.windows.net/powerbi/api/.default\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Create a ConfidentialClientApplication object\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'tenant_id' referenced before assignment"
     ]
    }
   ],
   "source": [
    "bob = Bob()\n",
    "settings = bob.get_settings()\n",
    "headers = bob.get_context()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the File Table Management \n",
    "The fabric File Table Management class present multiple methods for doing things like creating folders, listing folder content, writing to files, deleting files. This class takes the settings from the previous step and passes the `Client ID`, `Client Secret`, `Tenant Id` and `Workspace Name`. This classes methods do all the work of file and table management of the Lakehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = json.loads(settings['ServicePrincipal'])\n",
    "FF = File_Table_Management(\n",
    "    tenant_id=sp['TenantId'],\n",
    "    client_id=sp['AppId'],\n",
    "    client_secret=sp['AppSecret'],\n",
    "    workspace_name=settings['WorkspaceName']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the State  \n",
    "The `state.json` file is used for recording information into the Activty folder of the Lakehouse Files. The `state.json` file has LastRun date and time in UTC ISO(864) format. At the begining of the run the LastRun value determines how far back to read up to a maximum of 30 days of history from the current date. If for any reason the LastRun date is older than the maximum allowable then the Activity will read from the maximum date to the current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = File_Management()\n",
    "try:\n",
    "    config = await fm.read(file_name=\"state.yaml\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "if isinstance(config, str):\n",
    "    lastRun = json.loads(config).get(\"lastRun\")\n",
    "else:\n",
    "    lastRun = config.get(\"lastRun\")\n",
    "\n",
    "# if lastRun is recorded then proceed from there\n",
    "lastRun_tm = bob.convert_dt_str(lastRun)\n",
    "pivotDate = lastRun_tm.replace(hour=0, minute=0, second=0, microsecond=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def record_audits(DirectoryClient, FF:File_Table_Management, audit, pivotDate, pageIndex, outputPath):\n",
    "    if pageIndex == 1:\n",
    "        lakehouseFile = f\"{pivotDate.strftime('%Y%m%d')}.json\"\n",
    "    else:\n",
    "        lakehouseFile = f\"{pivotDate.strftime('%Y%m%d')}_{pageIndex}.json\"\n",
    "\n",
    "    ### This can now be streamed using the write_json_to_file method\n",
    "    # TODO: convert audits to json\n",
    "    #with open(outputFilePath, \"w\") as file:\n",
    "    #    file.write(json.dumps(audit))\n",
    "    FF.write_json_to_file(directory_client=DirectoryClient, file_name=lakehouseFile, json_data=audit)\n",
    "    #FF.upload_file_to_directory(directory_client=dc, local_path=outputPath, file_name=lakehouseFile)\n",
    "\n",
    "    flagNoActivity = False\n",
    "\n",
    "    pageIndex +=1 \n",
    "    audits = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling data from REST APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (pivotDate<datetime.now()):\n",
    "    audits = list()\n",
    "    pageIndex = 1\n",
    "    flagNoActivity = True\n",
    "\n",
    "    # keep the start and end time within a 24 hour period by adding 24 hours and removing 1 second \n",
    "    nextDate = (pivotDate + timedelta(hours=24)) + timedelta(seconds=-1)\n",
    "    rest_api = f\"admin/activityevents?startDateTime='{pivotDate.strftime('%Y-%m-%dT%H:%M:%SZ')}'&endDateTime='{nextDate.strftime('%Y-%m-%dT%H:%M:%SZ')}'\"\n",
    "\n",
    "    continuationUri=False\n",
    "    result = None\n",
    "\n",
    "    # python does not have a do while so this is the best way \n",
    "    # just need to break out of the loop when a condition is met\n",
    "    while(True):\n",
    "\n",
    "        if continuationUri:\n",
    "            result = await bob.invokeAPI(continuationUri)\n",
    "        else:\n",
    "            result = await bob.invokeAPI(rest_api=rest_api, headers=headers)\n",
    "\n",
    "\n",
    "        # check the https response code for 200\n",
    "        if \"ERROR\" in result:\n",
    "            print(result)\n",
    "            break\n",
    "        else:\n",
    "            # this is common to both parts of the if statement\n",
    "            if result.get(\"activityEventEntities\"):\n",
    "                audits.append(result.get(\"activityEventEntities\"))\n",
    "        \n",
    "            if result.get(\"continuaionURi\"):\n",
    "                continuationUri = result.get(\"continuationUri\")\n",
    "\n",
    "            # create the folder structure for the output path\n",
    "            localPath = f\"{settings.get('OutputPath')}/activity/{pivotDate.strftime('%Y')}/{pivotDate.strftime('%m')}/\"\n",
    "            lakehousePath = f\"{settings['LakehouseName']}.Lakehouse/Files/activity/{pivotDate.strftime('%Y')}/{pivotDate.strftime('%m')}/\"\n",
    "\n",
    "            # create the folder structure for the output path                       \n",
    "            #outputPath = bob.create_path(localPath)\n",
    "            outputPath = localPath\n",
    "\n",
    "            dc = await FF.create_directory(file_system_client=FF.fsc, directory_name=lakehousePath)\n",
    "\n",
    "            # do a for loop until all json arrays in audits are read and written to storage\n",
    "            for audit in audits:\n",
    "                await record_audits(dc, FF, audit, pivotDate, pageIndex, outputPath)\n",
    "\n",
    "            # get out of the inner while loop\n",
    "            break\n",
    "\n",
    "    pivotDate += timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environ = os.environ\n",
    "\n",
    "for e in environ:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"upon successful completion of the modules save the state\")\n",
    "with open('state.yaml', 'w') as file:\n",
    "    yaml.dump(data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dt_str(catalog_lastFulScan) - datetime.now() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
