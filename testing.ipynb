{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from app.utility.helps import Bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.modules.activity import main as Activity\n",
    "from app.modules.apps import main as Apps\n",
    "from app.modules.catalog import main as Catalog\n",
    "from app.modules.graph import main as Graph\n",
    "from app.modules.tenant import main as Tenant\n",
    "from app.modules.refreshhistory import main as RefreshHistory\n",
    "from app.modules.refreshables import main as Refreshables\n",
    "from app.modules.gateway import main as Gateway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = Bob()\n",
    "state = bob.get_state()\n",
    "settings = bob.get_settings()\n",
    "headers = bob.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activity': {'lastRun': '2024-04-03T13:56:00.986056Z'},\n",
       " 'catalog': {'lastFullScan': '2024-03-11T15:42:51.189058Z',\n",
       "  'lastRun': '2024-04-04T13:56:00.986116Z'},\n",
       " 'apps': {'lastRun': '2024-04-04T13:56:00.986056Z'},\n",
       " 'graph': {'lastRun': '2024-04-04T13:56:00.986056Z'},\n",
       " 'tenant': {'lastRun': '2024-04-04T13:56:00.986056Z'},\n",
       " 'refreshhistory': {'lastRun': '2024-04-04T13:56:00.986056Z'},\n",
       " 'refreshables': {'lastRun': '2024-04-05T13:56:00.986056Z'},\n",
       " 'gateway': {'lastRun': '2024-04-04T13:56:00.986056Z'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from croniter import croniter\n",
    "\n",
    "def scheduler(cron_time, last_run=None):\n",
    "\n",
    "    year = datetime.now().year\n",
    "    month = datetime.now().month\n",
    "    day = datetime.now().day\n",
    "\n",
    "    local_date = datetime(year, month, day, tzinfo=timezone.utc)\n",
    "    val = croniter(cron_time, local_date).get_next(datetime)\n",
    "    last_run = bob.convert_dt_str(last_run)\n",
    "    print(last_run)\n",
    "\n",
    "    # Determine if the current day of the week is the same as the value for day of the week in the cron value\n",
    "    current_day_of_week = datetime.now().strftime(\"%A\")\n",
    "    cron_day_of_week = cron_time.split(\" \")[4]\n",
    "\n",
    "\n",
    "    # Get the next scheduled datetime\n",
    "    next_datetime = val\n",
    "    print(next_datetime)\n",
    "\n",
    "    # Check if the current datetime matches the next scheduled datetime\n",
    "    if datetime.now().strftime(\"%Y-%m-%d\") == next_datetime.strftime(\"%Y-%m-%d\"):\n",
    "        print(\"Hello World, I am supposed to run today\")\n",
    "    else:\n",
    "        print(\"Goodnight World, I am sleeping\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_function_due(cron_syntax, last_run):\n",
    "    last_run_datetime = last_run\n",
    "\n",
    "    cron = croniter(cron_syntax, last_run_datetime)\n",
    "    next_run_datetime = cron.get_next(datetime)\n",
    "    \n",
    "    print(f\"What is the next run date value {next_run_datetime} and what is the current datetime {datetime.now()}\")\n",
    "\n",
    "    if next_run_datetime.strftime(\"%Y-%m-%d\") <= datetime.now().strftime(\"%Y-%m-%d\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the next run date value 2024-04-04 00:00:00 and what is the current datetime 2024-04-05 12:19:17.262328\n",
      "Function Activity is due to run\n",
      "What is the next run date value 2024-04-11 00:00:00 and what is the current datetime 2024-04-05 12:19:17.262661\n",
      "Function Apps is not due to run\n",
      "What is the next run date value 2024-04-06 00:00:00 and what is the current datetime 2024-04-05 12:19:17.262836\n",
      "Function Catalog is not due to run\n",
      "What is the next run date value 2024-04-06 00:00:00 and what is the current datetime 2024-04-05 12:19:17.263009\n",
      "Function Graph is not due to run\n",
      "What is the next run date value 2024-04-06 00:00:00 and what is the current datetime 2024-04-05 12:19:17.263175\n",
      "Function Tenant is not due to run\n",
      "What is the next run date value 2024-04-06 00:00:00 and what is the current datetime 2024-04-05 12:19:17.263428\n",
      "Function RefreshHistory is not due to run\n",
      "What is the next run date value 2024-04-05 00:00:00 and what is the current datetime 2024-04-05 12:19:17.263645\n",
      "Function Gateway is due to run\n",
      "What is the next run date value 2024-04-12 00:00:00 and what is the current datetime 2024-04-05 12:19:17.263862\n",
      "Function Refreshables is not due to run\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from croniter import croniter\n",
    "modules = settings.get(\"ApplicationModules\").replace(\" \",\"\").split(\",\")\n",
    "classes = [globals()[module] for module in modules]\n",
    "\n",
    "\n",
    "for module in modules:\n",
    "    cron = settings.get(f\"{module}_cron\")\n",
    "    run = state.get(f\"{module.lower()}\").get(\"lastRun\")\n",
    "\n",
    "    last_run = bob.convert_dt_str(run)    \n",
    "\n",
    "    \n",
    "\n",
    "    if is_function_due(cron,last_run):\n",
    "        print(f\"Function {module} is due to run\")\n",
    "    else:\n",
    "        print(f\"Function {module} is not due to run\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.get(\"Refreshables_cron\")\n",
    "state.get(\"refreshables\").get(\"lastRun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.get('activity').get('lastRun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = 'https://api.powerbi.com/v1.0/myorg/gateways'\n",
    "response = requests.get(url=api_url, headers=headers)\n",
    "results = response.json()\n",
    "print(response.status_code)\n",
    "gateways = list()\n",
    "for gateway in results['value']:\n",
    "    gateways.append(gateway.get(\"id\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = list()\n",
    "for id in gateways:\n",
    "    response = requests.get(f'https://api.powerbi.com/v1.0/myorg/gateways/{id}/datasources', headers=headers)\n",
    "    doc_results = response.json()\n",
    "    r.append(doc_results['value'])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gateways = list()\n",
    "\n",
    "for i in range(0, len(r)):\n",
    "    if isinstance(r[i], list):\n",
    "        for j in range(0, len(r[i])):\n",
    "            gateways.append(r[i][j])\n",
    "    else:\n",
    "        gateways.append(r[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gateways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list()\n",
    "\n",
    "for i in range(0,len(gateways)):\n",
    "    api_users = f'https://api.powerbi.com/v1.0/myorg/gateways/{gateways[i][\"gatewayId\"]}/datasources/{gateways[i][\"id\"]}/users'\n",
    "    response = requests.get(api_users, headers=headers)\n",
    "    results = response.json()\n",
    "    results['value'][0]['datasourceId'] = gateways[i][\"id\"]\n",
    "    results['value'][0]['gatewayId'] = gateways[i][\"gatewayId\"]\n",
    "    users.append(results['value'][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasource Connectivity  \n",
    "\n",
    "This only reports back connectivity to the datasource as an error. Also, you need to use the response.text as the JSON is not populated. A successful connection will report back as HTTP 200 while a failed connection will result in HTTP 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will be used for a template dictionary for a successful connection to the datasource\n",
    "status_base = {   \n",
    "    \"datasourceId\":\"\",\n",
    "    \"gatewayId\":\"\",\n",
    "    \"error\":\n",
    "    {\n",
    "        \"code\":\"success\",\n",
    "        \"pbi.error\":{ \n",
    "            \"code\":\"0\",\n",
    "            \"parameters\":{},\n",
    "            \"details\":[],\n",
    "            \"exceptionCulprit\":0\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status  = list()\n",
    "for i in range(0,len(gateways)):\n",
    "    api_status = f'https://api.powerbi.com/v1.0/myorg/gateways/{gateways[i][\"gatewayId\"]}/datasources/{gateways[i][\"id\"]}/status'\n",
    "    \n",
    "    response = requests.get(api_status, headers=headers)\n",
    "    if response.ok:\n",
    "        # response.json() is actually empty when it is a success\n",
    "        \n",
    "        status_base['datasourceId'] = gateways[i][\"id\"]\n",
    "        status_base['gatewayId'] = gateways[i][\"gatewayId\"]\n",
    "        status_base.get(\"error\").get(\"pbi.error\").get(\"details\").append({\"message\":\"success\",\"detail\":response.status_code})    \n",
    "        status.append(status_base)\n",
    "    else:\n",
    "        results = json.loads(response.text)\n",
    "        results[\"datasourceId\"] = gateways[i][\"id\"]\n",
    "        results[\"gatewayId\"] = gateways[i][\"gatewayId\"]\n",
    "        results.get(\"error\").get(\"pbi.error\").get(\"details\").append({\"message\":\"cannot connect\",\"detail\":response.status_code})    \n",
    "        status.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasources = list()\n",
    "\n",
    "for i in range(0,len(gateways)):\n",
    "    api_datasource = f'https://api.powerbi.com/v1.0/myorg/gateways/{gateways[i][\"gatewayId\"]}/datasources/{gateways[i][\"id\"]}'\n",
    "    response = requests.get(api_datasource, headers=headers)\n",
    "    results = response.json()\n",
    "    results.pop('@odata.context')\n",
    "    datasources.append(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "sender_email = 'brcampb@microsoft.com'\n",
    "receiver_email = 'brandonh.campbell@gmail.com'\n",
    "subject = 'Hello from Python!'\n",
    "body = 'This is a test email sent from a Python script.'\n",
    "\n",
    "msg = MIMEText(body)\n",
    "msg['Subject'] = subject\n",
    "msg['From'] = sender_email\n",
    "msg['To'] = receiver_email\n",
    "\n",
    "# Set up the SMTP server (e.g., Gmail)\n",
    "with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:\n",
    "    server.login(sender_email, 'your_password')\n",
    "    server.sendmail(sender_email, [receiver_email], msg.as_string())\n",
    "\n",
    "\n",
    "\n",
    "sender_email = 'your_email@example.com'\n",
    "receiver_email = 'recipient_email@example.com'\n",
    "subject = 'Hello from Python!'\n",
    "body = 'This is a test email sent from a Python script.'\n",
    "\n",
    "msg = MIMEText(body)\n",
    "msg['Subject'] = subject\n",
    "msg['From'] = sender_email\n",
    "msg['To'] = receiver_email\n",
    "\n",
    "# Set up the SMTP server (e.g., Outlook)\n",
    "with smtplib.SMTP('smtp.office365.com', 587) as server:\n",
    "    server.starttls()\n",
    "    server.login(sender_email, 'your_password')\n",
    "    server.sendmail(sender_email, [receiver_email], msg.as_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# Set up the SMTP server\n",
    "smtp_server = 'smtp.gmail.com'\n",
    "smtp_port = 587\n",
    "sender_email = 'your_email@example.com'\n",
    "password = 'your_password'\n",
    "\n",
    "# Create a message\n",
    "subject = 'Hello from Python!'\n",
    "body = 'This is a test email sent from a Python script.'\n",
    "msg = MIMEText(body)\n",
    "msg['Subject'] = subject\n",
    "msg['From'] = sender_email\n",
    "msg['To'] = 'recipient_email@example.com'\n",
    "\n",
    "# Send the email\n",
    "with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
    "    server.starttls()\n",
    "    server.login(sender_email, password)\n",
    "    server.sendmail(sender_email, [msg['To']], msg.as_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest_api = \"admin/capacities/refreshables\"\n",
    "# GET https://api.powerbi.com/v1.0/myorg/admin/groups?$expand=datasets\n",
    "# htpps://api.powerbi.com/v1.0/myorg/admin/groups?$expand=datasets\n",
    "rest_api = \"https://api.powerbi.com/v1.0/myorg/admin/groups?$expand=datasets&$top=5000\"\n",
    "\n",
    "response = requests.get(url=rest_api, headers=headers)\n",
    "workspaces = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in workspaces['value']:\n",
    "    group_id = item['id']\n",
    "    for dataset in item['datasets']:\n",
    "        dataset_id = dataset['id']\n",
    "        print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET https://api.powerbi.com/v1.0/myorg/groups/{groupId}/datasets/{datasetId}/refreshes\n",
    "refresh_history = list()\n",
    "\n",
    "for item in workspaces['value']:\n",
    "    group_id = item['id']\n",
    "    for dataset in item['datasets']:\n",
    "        dataset_id = dataset['id']\n",
    "        if dataset['isRefreshable']==True and dataset['addRowsAPIEnabled']==False:\n",
    "            rest_api = f\"https://api.powerbi.com/v1.0/myorg/groups/{group_id}/datasets/{dataset_id}/refreshes\"\n",
    "\n",
    "            response = requests.get(url=rest_api, headers=headers)\n",
    "            if response.ok:\n",
    "                results = response.json()\n",
    "                for result in results['value']:\n",
    "                    if len(result)>0:\n",
    "                        refresh_history.append(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fd = pd.DataFrame(refresh_history)\n",
    "fd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd[fd['requestId']=='9cbca636-ec64-4ff6-9dfe-9e2e5acc3056']['refreshAttempts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def normalize(df:pd.DataFrame(), base2:pd.DataFrame(), json_column='workspace_id'):\n",
    "    for row in df.itertuples():\n",
    "        column_number = df.columns.get_loc(json_column)+1\n",
    "        if isinstance(row[column_number], list) and len(row[column_number])>0:\n",
    "            for item in row[column_number]:\n",
    "                # item[id_name] = row.id\n",
    "                base2 = pd.concat([base2, df, pd.json_normalize(item)])\n",
    "                base2.drop(json_column, axis=1, inplace=True)\n",
    "        else:\n",
    "            if isinstance(row[column_number], dict):\n",
    "                print(\"Yes it is a dictionary\")\n",
    "                base2 = pd.concat([base2, df, pd.json_normalize(row[column_number])])\n",
    "                base2.drop(json_column, axis=1, inplace=True)\n",
    "    return base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = normalize(fd, pd.DataFrame(), 'refreshAttempts')\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = normalize(dd, pd.DataFrame(), 'serviceExceptionJson')\n",
    "de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "string_dict = \"{'id': '8271b9f0-3ff7-46b5-9f8a-5a3ba59d01b7', 'name': 'FabricMonitor', 'addRowsAPIEnabled': False, 'configuredBy': 'brandon.campbell@mngenvmcap084084.onmicrosoft.com', 'isRefreshable': True, 'isEffectiveIdentityRequired': False, 'isEffectiveIdentityRolesRequired': False, 'targetStorageMode': 'Abf', 'createdDate': '2024-03-27T18:42:49.663Z', 'contentProviderType': 'PbixInImportMode', 'upstreamDatasets': [], 'users': [], 'isInPlaceSharingEnabled': False}\"\n",
    "\n",
    "\n",
    "\n",
    "print(dict_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in dd.itertuples():\n",
    "    if isinstance(row.serviceExceptionJson, list) and len(row.serviceExceptionJson)>0:\n",
    "        for item in row.serviceExceptionJson:\n",
    "            print(item)\n",
    "    else:\n",
    "        if isinstance(row.serviceExceptionJson, str):\n",
    "            print(\"Yes it is a dictionary\")\n",
    "            print(row.serviceExceptionJson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api=\"https://api.powerbi.com/v1.0/myorg/admin/capacities/refreshables?$top=5000\"\n",
    "\n",
    "refreshables = list()\n",
    "\n",
    "response = requests.get(url=api, headers=headers)\n",
    "if response.ok:\n",
    "    results = response.json()\n",
    "    for result in results['value']:\n",
    "        refreshables.append(result)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(refresh_history)>=len(refreshables):\n",
    "    print(\"there is more information in refresh_history than in refreshables\")\n",
    "else:\n",
    "    print(\"there is more information in refreshables than in refresh_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_history[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.json_normalize(refreshables)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.json_normalize(refresh_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('refreshables.csv', index=False)\n",
    "df2.to_csv('refresh_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[['requestId','refreshAttempts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the DataFrame with the column 'refreshAttempts' is named 'df'\n",
    "df_expanded = pd.json_normalize(df3['refreshAttempts'])\n",
    "\n",
    "# Merge the expanded DataFrame with the original DataFrame\n",
    "df_merged = pd.concat([df3.drop('refreshAttempts', axis=1), df_expanded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unpivoted = df_merged.melt(id_vars=['requestId'], var_name='column', value_name='value')\n",
    "df_unpivoted.rename(columns={'requestId':'requestId','column':'column','value':'refreshAttempts'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unpivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Convert JSON column to DataFrame\n",
    "df_refreshAttempts = pd.json_normalize(df_unpivoted['refreshAttempts'])\n",
    "\n",
    "# Merge the original DataFrame with the new DataFrame\n",
    "df_merged = pd.concat([df_unpivoted.drop('refreshAttempts', axis=1), df_refreshAttempts], axis=1)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_history_clean = df_merged[['requestId','attemptId','startTime','endTime','serviceExceptionJson']]\n",
    "refresh_history_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_history_cleanest = df2.merge(refresh_history_clean, on='requestId', how='left')\n",
    "refresh_history_cleanest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_history_cleanest.drop(columns=['refreshAttempts'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_history_cleanest.to_csv('refresh_history_cleanest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
